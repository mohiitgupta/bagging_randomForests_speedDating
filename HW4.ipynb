{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "global_encoder_by_field = {}\n",
    "def get_encoding(column):\n",
    "    column = column.astype('category')\n",
    "    encoding = {}\n",
    "    for i, category in enumerate(column.cat.categories):\n",
    "        encoding[category] = i\n",
    "    global_encoder_by_field[column.name] = encoding\n",
    "    return column.cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'dating-full.csv'\n",
    "dating = pd.read_csv(filename)\n",
    "dating = dating.head(6500)\n",
    "cols_to_delete = ['race','race_o','field']\n",
    "for col in cols_to_delete:\n",
    "    del dating[col]\n",
    "\n",
    "dating[['gender']] = dating[['gender']].apply(get_encoding)\n",
    "\n",
    "partner_cols = ['pref_o_attractive','pref_o_sincere','pref_o_intelligence','pref_o_funny','pref_o_ambitious','pref_o_shared_interests']\n",
    "participant_cols = ['attractive_important', 'sincere_important', 'intelligence_important', 'funny_important', 'ambition_important', 'shared_interests_important']  \n",
    "\n",
    "total_partner = 0\n",
    "total_participant = 0 \n",
    "\n",
    "for i in range (0,6):\n",
    "    total_partner += dating[partner_cols[i]]\n",
    "    total_participant += dating[participant_cols[i]] \n",
    "\n",
    "for i in range(0,6):\n",
    "    dating[partner_cols[i]]/=total_partner\n",
    "    dating[participant_cols[i]]/=total_participant\n",
    "\n",
    "for i in range(0,6):\n",
    "    participant_mean = dating[participant_cols[i]].sum()/len(dating[participant_cols[i]])\n",
    "#     print ('Mean of ', participant_cols[i], ':', round(participant_mean, 2))\n",
    "for i in range(0,6): \n",
    "    partner_mean = dating[partner_cols[i]].sum()/len(dating[partner_cols[i]])\n",
    "#     print ('Mean of ', partner_cols[i], ':', round(partner_mean, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_binned_cols = ['gender', 'race', 'race_o', 'samerace', 'field', 'decision']   \n",
    "for column in dating:\n",
    "    if column not in non_binned_cols:\n",
    "        dating[column] = pd.cut(dating[column], 2, labels = [0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_dataset(t_frac, random_state, dataset):\n",
    "    '''\n",
    "    split dataset\n",
    "    '''\n",
    "    testset=dataset.sample(frac=t_frac,random_state=random_state)\n",
    "    trainset=dataset.drop(testset.index)\n",
    "    testset.to_csv(\"testSet.csv\", index = False)\n",
    "    trainset.to_csv(\"trainingSet.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_dataset(0.2, 47, dating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "\n",
    "    def __init__(self, attr, predicted_label):\n",
    "\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "        self.attr = attr\n",
    "        self.predicted_label = predicted_label\n",
    "\n",
    "\n",
    "    def PrintTree(self):\n",
    "        \n",
    "        if self.left:\n",
    "            self.left.PrintTree()\n",
    "        print (self.attr, \" \", self.predicted_label)\n",
    "        if self.right:\n",
    "            self.right.PrintTree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LABELS_LEN = 2\n",
    "MAX_DEPTH = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_gini(count_array, total_count):\n",
    "    gini = 1;\n",
    "    sum_prob = 0\n",
    "    if total_count <= 0:\n",
    "        return gini\n",
    "    for i in range(LABELS_LEN):\n",
    "        if i not in count_array:\n",
    "            count_array[i]=0\n",
    "        prob_i = count_array[i]/(1.0*total_count)\n",
    "        if prob_i != 0:\n",
    "            sum_prob += prob_i\n",
    "            gini -= prob_i**2\n",
    "    return gini\n",
    "\n",
    "def calculate_gini(labels):\n",
    "    return find_gini(labels.value_counts(), len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_features_labels(dataset):\n",
    "    features = dataset.drop(columns = ['decision'])\n",
    "    labels = dataset['decision']\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_label(labels):\n",
    "    counts = labels.value_counts()\n",
    "    predicted_label = counts.idxmax()\n",
    "    confidence = counts[predicted_label]/(1.0*len(labels))\n",
    "\n",
    "    return predicted_label, confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_branch(attr, attr_value, dataframe):\n",
    "    count_array = dataframe[dataframe[attr]==attr_value][\"decision\"].value_counts()\n",
    "    return count_array, np.sum(count_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_gini_gain(attr, dataframe, gini_sample):\n",
    "    count_array_left, total_eg_left = count_branch(attr, 0, dataframe)\n",
    "    count_array_right, total_eg_right = count_branch(attr, 1, dataframe)\n",
    "    \n",
    "    gini_left = find_gini(count_array_left, total_eg_left)\n",
    "    gini_right = find_gini(count_array_right, total_eg_right)\n",
    "    \n",
    "    gini_gain = gini_sample - (gini_left*total_eg_left + gini_right*total_eg_right)/(total_eg_left+total_eg_right)\n",
    "    return gini_gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_inference(root, test_features, test_labels):\n",
    "    correct_points = 0\n",
    "    predictions = []\n",
    "    for i in range(len(test_features)):\n",
    "        predicted_label = get_label_decision_tree(root, test_features.iloc[i])\n",
    "        \n",
    "        if test_labels[i] == predicted_label:\n",
    "            correct_points += 1\n",
    "        predictions.append(predicted_label)\n",
    "\n",
    "    accuracy = correct_points*100.0/len(test_labels)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_label_decision_tree(root, test_point):\n",
    "    if root.attr is None:\n",
    "        return root.predicted_label\n",
    "\n",
    "    if test_point[root.attr] == 0:\n",
    "        if root.left is not None:\n",
    "            return get_label_decision_tree(root.left, test_point)\n",
    "    if root.right is not None:\n",
    "        return get_label_decision_tree(root.right, test_point)\n",
    "    return root.predicted_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainingSet = pd.read_csv(\"trainingSet.csv\")\n",
    "testSet = pd.read_csv(\"testSet.csv\")\n",
    "training_features, training_labels = get_features_labels(trainingSet)\n",
    "test_features, test_labels = get_features_labels(testSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_decision_tree(trainingSet, depth, is_random_forest, excluded_features):    \n",
    "    predicted_label, confidence = predict_label(trainingSet['decision'])\n",
    "    if depth >= MAX_DEPTH or confidence == 100:\n",
    "#         print (predicted_label, \" with confidence \", confidence, \" depth is \", depth)\n",
    "        return Node(None, predicted_label)\n",
    "    \n",
    "    if len(trainingSet) <= 50:\n",
    "        return Node(None, predicted_label)\n",
    "\n",
    "    gini_sample = calculate_gini(trainingSet['decision'])\n",
    "    columns = trainingSet.columns\n",
    "    columns = columns.difference(excluded_features)\n",
    "    if is_random_forest:\n",
    "        num_samples = int(math.sqrt(len(columns)))\n",
    "        columns = random.sample(set(columns), num_samples)\n",
    "        \n",
    "    max_gini_gain = -100\n",
    "    max_split_attr = -100\n",
    "    for attr in columns:\n",
    "            gini_gain = calculate_gini_gain(attr, trainingSet, gini_sample)\n",
    "            if gini_gain > max_gini_gain:\n",
    "                max_gini_gain = gini_gain\n",
    "                max_split_attr = attr\n",
    "#     print (max_gini_gain, \" attr \", max_split_attr)\n",
    "\n",
    "    left_trainingSet = trainingSet[trainingSet[max_split_attr]==0]\n",
    "    right_trainingSet = trainingSet[trainingSet[max_split_attr]==1]\n",
    "\n",
    "    node = Node(max_split_attr, predicted_label)\n",
    "\n",
    "    if len(left_trainingSet) > 0:\n",
    "        excluded_features.add(max_split_attr)\n",
    "        node.left = create_decision_tree(left_trainingSet, depth+1, is_random_forest, excluded_features)\n",
    "        excluded_features.remove(max_split_attr)\n",
    "    if len(right_trainingSet) > 0:\n",
    "        excluded_features.add(max_split_attr)\n",
    "        node.right = create_decision_tree(right_trainingSet, depth+1, is_random_forest, excluded_features)\n",
    "        excluded_features.remove(max_split_attr)\n",
    "    return node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = create_decision_tree(trainingSet, 0, False, {\"decision\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_inference(root, test_features, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_inference(root, training_features, training_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "root.PrintTree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=[1,2,3]\n",
    "b=np.array([3,2,5])\n",
    "np.sum(a==b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def do_inference_bagging(baggedTrees, test_features, test_labels):\n",
    "    predicted_labels = []\n",
    "    for i in range(len(test_features)):\n",
    "        predicted_label_array = []\n",
    "        for j in range(len(baggedTrees)):\n",
    "            predicted_label_i = get_label_decision_tree(baggedTrees[j], test_features.iloc[i])\n",
    "            predicted_label_array.append(predicted_label_i)\n",
    "        predicted_label = max(predicted_label_array, key = predicted_label_array.count)\n",
    "        \n",
    "        predicted_labels.append(predicted_label)\n",
    "    correct_labels = np.sum(predicted_labels == test_labels)\n",
    "    accuracy = 100*correct_labels/(1.0*len(test_labels))\n",
    "    return predicted_labels, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_bagged_trees(trainingSet):\n",
    "    baggedTrees = []\n",
    "    for i in range(30):\n",
    "        sampledSet= trainingSet.sample(frac=1,replace=True)\n",
    "        root = create_decision_tree(sampledSet, 0, False, {\"decision\"})\n",
    "        baggedTrees.append(root)\n",
    "    return baggedTrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bagging(trainingSet, testSet):\n",
    "    baggedTrees = create_bagged_trees(trainingSet)\n",
    "    predictions, accuracy = do_inference_bagging(baggedTrees, test_features, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "baggedTrees = create_bagged_trees(trainingSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions, test_accuracy = do_inference_bagging(baggedTrees, test_features, test_labels)\n",
    "print(test_accuracy)\n",
    "train_predictions, train_accuracy = do_inference_bagging(baggedTrees, training_features, training_labels)\n",
    "print(train_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainingSet.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# col=trainingSet.columns\n",
    "# col = col\n",
    "# # print(col)\n",
    "# r={\"decision\",\"age1\"}\n",
    "# col=col.difference(r)\n",
    "# num = int(math.sqrt(len(col)))\n",
    "# col=random.sample(set(col), num)\n",
    "# print (col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def adhoc_recursion(l, side, depth):\n",
    "#     if depth == 3:\n",
    "#         print(l)\n",
    "#         return\n",
    "#     if side:\n",
    "#         l.append(1)\n",
    "#     else:\n",
    "#         l.append(2)\n",
    "#     adhoc_recursion(l, True, depth+1)\n",
    "#     del l[-1]\n",
    "#     adhoc_recursion(l, False, depth+1)\n",
    "#     del l[-1]\n",
    "    \n",
    "# l=[]\n",
    "# side = True\n",
    "# adhoc_recursion(l,side, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_random_forest(trainingSet):\n",
    "    rfTrees = []\n",
    "    for i in range(30):\n",
    "        sampledSet= trainingSet.sample(frac=1,replace=True)\n",
    "        root = create_decision_tree(sampledSet, 0, True, {\"decision\"})\n",
    "        rfTrees.append(root)\n",
    "    return rfTrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rfTrees =create_random_forest(trainingSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions, test_accuracy=do_inference_bagging(rfTrees, test_features, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predictions, train_accuracy=do_inference_bagging(rfTrees, training_features, training_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
